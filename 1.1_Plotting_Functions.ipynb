{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains function definitions to make the visualization and evaluation processes less cluttered and more interactive.\n",
    "\n",
    "This code is in notebook form to make it more readable.\n",
    "The same code is available as a Julia script (.jl) file for importing it into other scripts.\n",
    "\n",
    "Some of this code requires the Julia package Interact along with the Jupyter extension WebIO. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.webio.node+json": {
       "children": [],
       "instanceArgs": {
        "namespace": "html",
        "tag": "div"
       },
       "nodeType": "DOM",
       "props": {},
       "type": "node"
      },
      "text/html": [
       "<div style=\"padding: 1em; background-color: #f8d6da; border: 1px solid #f5c6cb; font-weight: bold;\">\n",
       "<p>The WebIO Jupyter extension was not detected. See the\n",
       "<a href=\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\" target=\"_blank\">\n",
       "    WebIO Jupyter integration documentation\n",
       "</a>\n",
       "for more information.\n",
       "</div>\n"
      ],
      "text/plain": [
       "WebIO._IJuliaInit()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Colors\n",
    "using ProgressMeter\n",
    "using Plots\n",
    "using Interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power grid creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example_plot (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that plots a graph and indicates the node with maximum closeness centrality (slack bus) by color\n",
    "function example_plot(n, n0, p, q, r; size=2, reps=100)\n",
    "\n",
    "    grid = create_grid(n, n0, p, q, r)\n",
    "\n",
    "    #println(\"exemplary graph:\")\n",
    "\n",
    "    types = ones(Int,n)\n",
    "    slack_index = findmax(closeness_centrality(grid.graph))[2]\n",
    "    types[slack_index] = 2\n",
    "    colors = [colorant\"tomato2\", colorant\"royalblue\"]\n",
    "    \n",
    "    solar_map = set_prosumers(n,0,0,slack_index)\n",
    "    flowtest_p_timeseries = power_randomdraws(solar_map.old, solar_dict_default, consumer_dict_default,\n",
    "                                              0, reps, slack_index)   \n",
    "    caps = ceil.(1.75*max_flows(grid,flowtest_p_timeseries, slack_index), digits=16)\n",
    "    \n",
    "    \n",
    "    widths = size*caps/maximum(caps)\n",
    "    \n",
    "    loc_x = vertices_loc(grid,1)\n",
    "    loc_y = vertices_loc(grid,2)\n",
    "    gplot(grid.graph, loc_x, loc_y, \n",
    "          nodefillc=colors[types],\n",
    "          nodesize=types.+size,# NODESIZE=1,\n",
    "          edgelinewidth=widths, EDGELINEWIDTH = size, edgestrokec=colorant\"black\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grid_specs (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that computes and prints statistics about graphs created by the power grid genaration algorithm\n",
    "function grid_specs(n, n0, p, q, r; reps=1000)\n",
    "    \n",
    "    slacks, lengths, edges, dists, degrees, lcc, gcc, cycles = [], [], [], [], [], [], [], []\n",
    "    \n",
    "    for i in 1:reps\n",
    "        grid = create_grid(n, n0, p, q, r)\n",
    "        slack_index = findmax(closeness_centrality(grid.graph))[2]\n",
    "        append!(edges, ne(grid))\n",
    "        append!(degrees, mean(degree(grid.graph)) )\n",
    "        for j in nv(grid)\n",
    "            append!(dists, gdistances(grid, j))\n",
    "        end\n",
    "        append!(slacks,gdistances(grid, slack_index))\n",
    "        append!(lcc, mean(local_clustering_coefficient(grid.graph)) )\n",
    "        append!(gcc, global_clustering_coefficient(grid.graph) )\n",
    "        append!(cycles, (simplecyclescount(DiGraph(grid.graph))-ne(grid))/2 )\n",
    "        append!(lengths, sum(line_lengths(grid)))\n",
    "    end\n",
    "    \n",
    "    println(\"average graph properties:\")\n",
    "    println()\n",
    "    println(\"edges: \",mean(edges),\" +- \",std(edges))\n",
    "    println(\"geodesic distances: \",mean(dists),\" +- \",std(dists))\n",
    "    println(\"geodesic distance to slack bus: \",mean(slacks),\" +- \",std(slacks))\n",
    "    println(\"degree: \", mean(degrees),\" +- \",std(degrees))\n",
    "    println(\"mean local clustering coefficient: \", mean(lcc),\" +- \",std(lcc))\n",
    "    println(\"global clustering coefficient: \",mean(gcc),\" +- \",std(gcc))\n",
    "    println(\"fundamental cycles: \", mean(cycles),\" +- \",std(cycles))\n",
    "    println(\"total line length: \", mean(lengths),\" +- \",std(lengths))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_hist (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that concatenates all arrays/lists within a distionary to a single list\n",
    "function dict_hist(dict)\n",
    "    \n",
    "    list = []\n",
    "    for key in keys(dict)\n",
    "        for e in dict[key]\n",
    "            append!(list, e)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return list\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "combo_hist (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# struct with two fields\n",
    "struct combo_struct\n",
    "    list\n",
    "    ratio\n",
    "end\n",
    "\n",
    "# function to combine dictionaries of consumption + supply time series, and save the combination ratio\n",
    "function combo_hist(c_dict, s_dict; ratio=1)\n",
    "    \n",
    "    list = []\n",
    "    for c_key in keys(c_dict)\n",
    "        for s_key in keys(s_dict)\n",
    "            append!(list, ratio*s_dict[s_key]-c_dict[c_key])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return combo_struct(sort(list),ratio)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Parameter Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rangefinder_test (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that calculates the maximum span of adverse influence parameters that a type of power grid can cope with\n",
    "# depending on the number of different grid instances and days of simulation\n",
    "function rangefinder_test(path; grids_range=1:2, days_range=1:2, reps=10, safety=1.5, test_runs=100)\n",
    "   \n",
    "    locs = 1\n",
    "    ftr = test_runs\n",
    "    rtr = ftr\n",
    "    \n",
    "    ratio_span = Dict()\n",
    "    P2_span = Dict()\n",
    "    \n",
    "    #better use one for loop with parameter tuples\n",
    "    #@distributed \n",
    "    for grids in grids_range\n",
    "        \n",
    "        #@distributed \n",
    "        for days in days_range\n",
    "            \n",
    "            ratio_list = []\n",
    "            P2_list = []\n",
    "            \n",
    "            #@distributed \n",
    "            for rep in 1:reps\n",
    "                append!(ratio_list, ratio_finder(\"none\", 0, 0, 0, 0, 0.99, 1., 10.,\n",
    "                                                 grids=grids, locs=locs, safety=safety, ftr=ftr, rtr=rtr, days=days))\n",
    "                append!(P2_list, P2_finder(\"none\", 0, 0, 0, 0, 0.99, 10, 99,\n",
    "                                           grids=grids, locs=locs, safety=safety, ftr=ftr, rtr=rtr, days=days))\n",
    "            end\n",
    "            \n",
    "            key = (grids, days)\n",
    "            \n",
    "            ratio_span[key] = maximum(ratio_list)-minimum(ratio_list)\n",
    "            P2_span[key] = maximum(P2_list)-minimum(P2_list)\n",
    "            \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    xs = collect(grids_range)\n",
    "    ys = collect(days_range)\n",
    "    \n",
    "    function rs(x,y)\n",
    "        return ratio_span[(x,y)]\n",
    "    end\n",
    "    function ps(x,y)\n",
    "        return P2_span[(x,y)]\n",
    "    end\n",
    "    \n",
    "    title_rest =  \" span at $(reps) reps \\n for safety=$(safety)\n",
    "                    and flowtest_runs=$(ftr)\"\n",
    "    filename_rest =  \"_span_at_$(reps)_reps_for_safety=$(safety)\n",
    "                      _and_flowtest_runs=$(ftr)\"\n",
    "    \n",
    "    h1 = heatmap(xs, ys, rs, title= \"ratio\"*title_rest, xlabel=\"grids\", ylabel=\"days\")\n",
    "    h2 = heatmap(xs, ys, ps, title= \"P2\"*title_rest, xlabel=\"grids\", ylabel=\"days\")\n",
    "    plot(h1,h2, size=(1000,300))\n",
    "    savefig(path*\"/ratio_and_P2\"*filename_rest*\".png\")\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rangefinder_test_2 (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# improved version of the above function that calculates the maximum span of adverse influence parameters that a type of power grid can cope with\n",
    "# depending on the number of different grid instances, days of simulation, and safety factor/ number of test runs used to determine the initial grid line capacities\n",
    "function rangefinder_test_2(;path=plot_path, reps=10,\n",
    "                            grids_range=1:2, days_range=1:2, safety_range=1.5:0.5:2, test_runs_range=100:100:200)\n",
    "   \n",
    "    parameter_list = Dict()\n",
    "    locs = 1\n",
    "        \n",
    "    i = 1\n",
    "    for grids in grids_range\n",
    "        for days in days_range\n",
    "            for safety in safety_range\n",
    "                for test_runs in test_runs_range\n",
    "                    for rep in 1:reps\n",
    "                        parameter_list[i] = (grids,days,safety,test_runs,rep)\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    #@distributed\n",
    "    for p in goodvals(parameter_list)\n",
    "        grids,days,safety,test_runs,rep = p                \n",
    "        ftr = test_runs\n",
    "        rtr = ftr\n",
    "        \n",
    "        ratio = ratio_finder(\"none\", 0, 0, 0, 0, 0.99, 1., 10.,\n",
    "                             grids=grids, locs=locs, safety=safety, ftr=ftr, rtr=rtr, days=days)\n",
    "        P2 = P2_finder(\"none\", 0, 0, 0, 0, 0.99, 10, 99,\n",
    "                  grids=grids, locs=locs, safety=safety, ftr=ftr, rtr=rtr, days=days)\n",
    "        \n",
    "        CSV.write(path*\"/\"*filename,Tables.table(tab),delim=\"\\t\",header=false)\n",
    "    end   \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sustainant_test_2d (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that returns the minimum sustainant value achieved by a type of grid in the absence of adverse influences (prosumers)\n",
    "# depending on the safety factor and number of test runs for the initial line capacities\n",
    "function sustainant_test_2d(perf_days, grids, max_testruns, testruns_step, max_safety, safety_step) #todo\n",
    "    \n",
    "    delta = Dict()\n",
    "    \n",
    "    N = 100\n",
    "    res = 60\n",
    "    steps_per_day = Int(ceil(86400/res))\n",
    "    solar_dict = smoother(solar_dict_default,res)\n",
    "    consumer_dict = smoother(consumer_dict_default,res)\n",
    "    solar_map = zeros(N)\n",
    "    prosumption_ratio = 0\n",
    "    \n",
    "    caps = Dict()\n",
    "    \n",
    "    for g in 1:grids\n",
    "        \n",
    "        grid = create_grid(N, maximum([Int(floor(N*0.15)),1]), 0.15, 0.15, 0.2)\n",
    "        slack_index = findmax(closeness_centrality(grid.graph))[2]\n",
    "\n",
    "        test_series = balance_randomdraws(solar_map, solar_dict, consumer_dict, prosumption_ratio, max_testruns+1,\n",
    "                                          slack_index)\n",
    "        sus_series = balance_randomdraws(solar_map, solar_dict, consumer_dict, prosumption_ratio,\n",
    "                                         perf_days*steps_per_day, slack_index)\n",
    "        \n",
    "        for safety in 1.:safety_step:max_safety\n",
    "            for t in 1:testruns_step:max_testruns+1\n",
    "                key = (t, safety)\n",
    "                caps[key] = safety*max_any_flows(grid, test_series.balance[1:t,:])\n",
    "\n",
    "                if haskey(delta,key) == false\n",
    "                    delta[key] = []\n",
    "                end\n",
    "                sus = system_performance_series(grid, caps[key], sus_series, slack_index)\n",
    "                append!(delta[key],sus.delta)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for key in keys(delta)\n",
    "        delta[key] = minimum(delta[key])\n",
    "    end\n",
    "    \n",
    "    return delta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict2plot (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to plot the minimum sustainant (computed by function above) as a heatmap\n",
    "# values below 0.99 are set to 0\n",
    "function dict2plot(dict)\n",
    "    \n",
    "    all_x = [key[1] for key in keys(dict)]\n",
    "    all_y = [key[2] for key in keys(dict)]\n",
    "    \n",
    "    max_x = maximum(all_x)\n",
    "    max_y = maximum(all_y)\n",
    "    \n",
    "    step_x = min_diff(all_x)\n",
    "    step_y = round(min_diff(all_y),digits=2)\n",
    "    \n",
    "    for key in keys(dict)\n",
    "        if dict[key] < 0.99\n",
    "            dict[key] = 0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    xs = [t for t in 1:step_x:max_x]\n",
    "    ys = [s for s in 1:step_y:max_y]\n",
    "    p(x,y) = dict[(x,y)]\n",
    "    \n",
    "    plot(heatmap(xs, ys, p), title = \"minimum delta = tau value\",\n",
    "         xlabel=\"captest runs\", ylabel=\"safety factor\")\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qf (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that calculates the inverse of a quantile (also called quantile function = qf)\n",
    "function qf(array,limit)\n",
    "    frac = length(findall(x -> x<limit,array)) / length(array)\n",
    "    return frac\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "betterkeys (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that returns keys of a dictionary in a sorted order (rather than random)\n",
    "function betterkeys(dict)\n",
    "    return sort([key for key in keys(dict)])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst_from_list (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to generate an estimated sample from a list of quantiles and their probabilities\n",
    "# the histogram is created with the lowest (=worst) values possible\n",
    "function worst_from_list(p_values, qs; counts=50*60*24*60)\n",
    "    \n",
    "    values = []\n",
    "    for i in 1:(length(p_values)-1)\n",
    "        \n",
    "        low = qs[i]\n",
    "        reps = counts * (p_values[i+1]-p_values[i])\n",
    "        append!(values,fill(low,Int(ceil(reps))))\n",
    "    end\n",
    "    return values\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "superplot (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# workaround function to add a super-title to an existing plot or grid of subplots\n",
    "function superplot(args...; title=\"title\", layout = length(args), size=(1200,800))\n",
    "    \n",
    "    y = [1,2,3] \n",
    "    diy_title = Plots.scatter(y, marker=0,markeralpha=0, annotations=(2, y[2], Plots.text(title, :center)),\n",
    "                              axis=false, leg=false, grid=false)\n",
    "\n",
    "    Plots.plot( diy_title, Plots.plot(args..., layout=layout, size=size), layout=(2, 1))\n",
    "    #layout=grid(2, 1, heights=[0.1, 0.9]) #maybe 1.5 fixes grid?\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake_histogram_data (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to generate a fake histogram (column plot) from a list of quantiles and their probabilities  \n",
    "function fake_histogram_data(ps, qs)\n",
    "    \n",
    "    xs = []\n",
    "    ys = []\n",
    "    \n",
    "    append!(xs,qs[1])\n",
    "    append!(ys,ps[1]^2/ps[2])\n",
    "    \n",
    "    for i in 2:length(ps)\n",
    "        \n",
    "        append!(xs,[qs[i-1],qs[i]])\n",
    "        append!(ys,[ps[i]-ps[i-1], ps[i]-ps[i-1]])\n",
    "    end\n",
    "    \n",
    "    return (xs,ys)\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contour_with_error (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to create a contour plot from 3D data along with another subplot displaying the error\n",
    "function contour_with_error(x, y, z, z_err, ;z_max=maximum(z), xlabel=\"x\", ylabel=\"y\", zlabel=\"z\", elabel=\"z error\",\n",
    "                            cmap=:Spectral_11, err_cmap=:inferno, dpi=100,\n",
    "                            xlog=true, frame_fac=0, sep_cmap=true, clevels=500, cexp=-10) \n",
    "    \n",
    "    cmap = cgrad(cmap, scale=x->-log10(1-x+1*10. ^cexp))\n",
    "    #err_cmap = cgrad(cmap, scale=x->-log10(1-x+1*10. ^(cexp/50)))\n",
    "    \n",
    "    clims = (0, z_max)\n",
    "    err_clims = :none #(0,1)\n",
    "    \n",
    "    if sep_cmap == false\n",
    "        err_cmap = cmap\n",
    "        err_clims = clims\n",
    "    end\n",
    "    \n",
    "    if xlog == true\n",
    "        xscale = :log10\n",
    "        xspan = log10(x[end]) - log10(x[1])\n",
    "        xlims = (10^(x[1]-frame_fac*xspan), 10^(x[end]+frame_fac*xspan) )\n",
    "    else\n",
    "        xscale = :identity\n",
    "        xspan = x[end]-x[1]\n",
    "        xlims = (x[1]-frame_fac*xspan, x[end]+frame_fac*xspan)\n",
    "    end\n",
    "    \n",
    "    yspan = y[end]-y[1]\n",
    "    ylims = (y[1]-frame_fac*yspan, y[end]+yspan*frame_fac)\n",
    "    \n",
    "    vp = contour(x, y, z, xlabel=xlabel, ylabel=ylabel, color=cmap, fill=true, levels=clevels, colorbar=:right,\n",
    "                 title=zlabel, yticks=y, xtickfontrotation=90, clims=clims, #xlims=xlims, ylims=ylims,\n",
    "                 right_margin=dpi/100*5*mm, xscale=xscale, xticks=(x,x), framestyle=:box)\n",
    "    \n",
    "    ep = contour(x, y, z_err, xlabel=xlabel, ylabel=ylabel, color=err_cmap, fill=true, levels=clevels, colorbar=:right,\n",
    "                 title=elabel, yticks=y, xtickfontrotation=90, clims=err_clims, #xlims=xlims, ylims=ylims,\n",
    "                 right_margin=dpi/100*5*mm, xscale=xscale, xticks=(x,x), framestyle=:box)\n",
    "    \n",
    "    return plot(vp, ep, layout=@layout[a b], size=(1000,500))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mod_array (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that returns values from an array even for index values larger than the array length (by cycling back to the first array element)\n",
    "function mod_array(number,array)\n",
    "    return array[mod(number,1:length(array))]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marginal_plot (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to create two marginal line plots from 3D data\n",
    "function marginal_plot(x, y, z, z_err; xlab=\"x\", xlabel=\"x\", ylabel=\"y\", zlabel=\"z\",cmap=:viridis, #:rainbow1 :RdYlBu_3 :rainbow_bgyr_35_85_c73_n256\n",
    "                       xlog=true, zlog=false, frame_fac=0, dpi=100)#0.05)\n",
    "    \n",
    "    if xlog == true\n",
    "        xscale = :log10\n",
    "        xspan = log10(x[end]) - log10(x[1])\n",
    "        xlims = ( 10^(x[1]-frame_fac*xspan), 10^(x[end]+frame_fac*xspan) )\n",
    "    else\n",
    "        xscale = :identity\n",
    "        xspan = x[end]-x[1]\n",
    "        xlims = (x[1]-frame_fac*xspan, x[end]+frame_fac*xspan)\n",
    "    end\n",
    "    \n",
    "    if zlog == true\n",
    "        zscale = :log10\n",
    "        zspan = log10(maximum(z)) - log10(minimum(z))\n",
    "        zlims = ( 10^(minimum(z)-frame_fac*zspan), 10^(maximum(z)+frame_fac*zspan) )\n",
    "    else\n",
    "        zscale = :identity\n",
    "        zspan = maximum(z)-minimum(z)\n",
    "        zlims = (minimum(z)-frame_fac*zspan, maximum(z)+zspan*frame_fac)\n",
    "    end\n",
    "    \n",
    "    yspan = y[end]-y[1]\n",
    "    ylims = (y[1]-frame_fac*yspan, y[end]+yspan*frame_fac)\n",
    "    \n",
    "    styles =  [:solid, :dash, :dot, :dashdot,]\n",
    "    \n",
    "    xp = plot(framestyle=:box)\n",
    "    for i in 1:length(y)\n",
    "        line_c = cgrad(cmap)[(i-1)/(length(y)-1)]\n",
    "        line_s = mod_array(i,styles)\n",
    "        plot!(x,z[i,:],xlabel=xlabel,ylabel=zlabel,label=\"$(ylabel) = $(y[i])\",leg=:outertop, #xlims=xlims, ylims=zlims,\n",
    "              linewidth=2,linecolor=line_c, xticks=(x,x), xtickfontrotation=90, xscale=xscale, yscale=zscale,\n",
    "              ribbon=z_err, fillalpha=0.2, fillcolor=line_c, linestyle=line_s, \n",
    "              right_margin=dpi/100*5*mm, top_margin=dpi/100*5*mm)\n",
    "    end\n",
    "    \n",
    "    yp = plot(framestyle=:box)\n",
    "    for j in 1:length(x)\n",
    "        line_c = cgrad(cmap)[(j-1)/(length(x)-1)]\n",
    "        line_s = mod_array(j,styles)\n",
    "        plot!(y,z[:,j],xlabel=ylabel,ylabel=zlabel,label=\"$(xlab) = $(x[j])\",leg=:outertop, #xlims=ylims, ylims=zlims,\n",
    "              linewidth=2,linecolor=line_c, xticks=y, xtickfontrotation=90, xscale=:identity,\n",
    "              ribbon=z_err, fillalpha=0.2, fillcolor=line_c, linestyle=line_s,\n",
    "              right_margin=dpi/100*15*mm, top_margin=dpi/100*5*mm)\n",
    "    end\n",
    "    \n",
    "    return plot(xp, yp, layout=@layout[a b], size=(1000,600))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_missing_values (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to get all element of a list except for one\n",
    "function find_missing_values(selectable, selected)\n",
    "    \n",
    "    vals = []\n",
    "    for i in selectable\n",
    "        if (i in selected) == false\n",
    "            append!(vals,i)\n",
    "        end\n",
    "    end\n",
    "    return vals\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delete_rows (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to delete a row of a data frame\n",
    "function delete_rows(df, name, value)\n",
    "    df[df[!,name].!=value,:]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resilience_freq (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that returns the frequency of the sustainant deviating from the ideal value by more than a threshold\n",
    "function resilience_freq(mean_weighted_deviations; threshold=1/99/365) #10^-5)\n",
    "    return length(filter(x -> x<=threshold, mean_weighted_deviations))/length(mean_weighted_deviations)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indicator_chi (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple possible influence density functions\n",
    "\n",
    "normy = 1#/(9900-4950)/(50-0.995)\n",
    "decreasing_chi(np, rp) = normy * (100-np) * (10-rp) \n",
    "\n",
    "normy2 = 1# /(10-0.1)/99\n",
    "uniform_chi(np ,rp) = normy2\n",
    "\n",
    "indicator_chi(np, rp) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qmc_summary (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that calculates the resilience value of a given response strategy from the QMC samples covering the influence space\n",
    "# the QMC samples are read from their folder and a new .csv file containing the summary is created in the parent directory\n",
    "function qmc_summary(results_path; uniform_chi=uniform_chi, non_uniform_chi=decreasing_chi)\n",
    "    \n",
    "    @manipulate for b = button(\"Summarize QMC sampling results\"; value=0)\n",
    "        if b > 0\n",
    "            b = 0\n",
    "\n",
    "            results_directory = readdir(results_path)\n",
    "            for allocation_folder in results_directory\n",
    "\n",
    "                if occursin(\"csv\",allocation_folder) == false\n",
    "\n",
    "                    allocation_directory = readdir(results_path*\"/\"*allocation_folder)\n",
    "                    @showprogress for parameter_folder in allocation_directory\n",
    "\n",
    "                        if occursin(\"csv\",parameter_folder) == false\n",
    "\n",
    "                            samples = Dict()        \n",
    "                            counts = 0\n",
    "                            non_uni_prob_sum = 0\n",
    "                            uni_delta_sum, uni_tau_sum, uni_delta_squaresum, uni_tau_squaresum = 0, 0, 0, 0\n",
    "                            non_uni_delta_sum, non_uni_tau_sum, non_uni_delta_squaresum, non_uni_tau_squaresum = 0, 0, 0, 0\n",
    "\n",
    "                            folder = readdir(results_path*\"/\"*allocation_folder*\"/\"*parameter_folder)\n",
    "                            for file in folder\n",
    "                                \n",
    "                                thing = results_path*\"/\"*allocation_folder*\"/\"*parameter_folder*\"/\"*file\n",
    "                                #params = CSV.read(thing, DataFrame, transpose=true,\n",
    "                                                   #limit=1, drop=collect(24:45))\n",
    "                                devs = CSV.read(thing, DataFrame, skipto=27, header=26)\n",
    "\n",
    "                                delta_devs = devs.\"delta mean weighted deviation\"\n",
    "                                tau_devs = devs.\"tau mean weighted deviation\"\n",
    "\n",
    "                                delta_freq = 1.0 #resilience_freq(delta_devs)\n",
    "                                tau_freq = resilience_freq(tau_devs)\n",
    "\n",
    "                                file = string(file)\n",
    "                                P2 = value_from_filename(file, \"P2\")\n",
    "                                ratio = value_from_filename(file, \"rp\")\n",
    "                                key = (P2, ratio)\n",
    "                                \n",
    "                                counts += 1\n",
    "                                \n",
    "                                uni_inf_prob = uniform_chi(P2,ratio)\n",
    "                                non_uni_inf_prob = non_uniform_chi(P2,ratio)\n",
    "                                non_uni_prob_sum += non_uni_inf_prob\n",
    "                                \n",
    "                                samples[key] = [uni_inf_prob, non_uni_inf_prob, delta_freq, tau_freq]\n",
    "                                \n",
    "                                uni_delta_sum += delta_freq * uni_inf_prob\n",
    "                                uni_tau_sum += tau_freq * uni_inf_prob\n",
    "                                \n",
    "                                uni_delta_squaresum += (delta_freq * uni_inf_prob)^2\n",
    "                                uni_tau_squaresum += (tau_freq * uni_inf_prob)^2\n",
    "                                \n",
    "                                non_uni_delta_sum += delta_freq * non_uni_inf_prob\n",
    "                                non_uni_tau_sum += tau_freq * non_uni_inf_prob\n",
    "                                \n",
    "                                non_uni_delta_squaresum += (delta_freq * non_uni_inf_prob)^2\n",
    "                                non_uni_tau_squaresum += (tau_freq * non_uni_inf_prob)^2\n",
    "                                \n",
    "                            end\n",
    "                            \n",
    "                            max_P2 = value_from_filename(parameter_folder, \"max_P2\")\n",
    "                            max_ratio = value_from_filename(parameter_folder, \"max_rp\")\n",
    "                            allocation = string_value_from_filename(parameter_folder, \"alloc\")\n",
    "                            line_budget_factor = value_from_filename(parameter_folder, \"line_bf\")\n",
    "                            new_lines = value_from_filename(parameter_folder, \"new_l\")\n",
    "                            battery_budget_factor = value_from_filename(parameter_folder, \"batt_bf\")\n",
    "                            battery_reliance = value_from_filename(parameter_folder, \"b_rel\")\n",
    "\n",
    "                            qmc_area = max_P2 * (max_ratio-0.1)\n",
    "                            \n",
    "                            \n",
    "                            #normalizing a posteriori\n",
    "                            non_uni_delta_sum *= (counts/qmc_area/non_uni_prob_sum)\n",
    "                            non_uni_tau_sum *= (counts/qmc_area/non_uni_prob_sum)\n",
    "                            non_uni_delta_squaresum *= (counts/qmc_area/non_uni_prob_sum)^2\n",
    "                            non_uni_tau_squaresum *= (counts/qmc_area/non_uni_prob_sum)^2\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            uni_delta_integral = uni_delta_sum * qmc_area/counts\n",
    "                            uni_tau_integral = uni_tau_sum * qmc_area/counts\n",
    "                            \n",
    "                            non_uni_delta_integral = non_uni_delta_sum * qmc_area/counts\n",
    "                            non_uni_tau_integral = non_uni_tau_sum * qmc_area/counts\n",
    "                            \n",
    "                            if (uni_delta_squaresum - (1/counts)*uni_delta_sum^2) < 0\n",
    "                                uni_delta_error = 0\n",
    "                            else\n",
    "                                uni_delta_error = qmc_area /sqrt(counts^2-counts) * \n",
    "                                                  sqrt( uni_delta_squaresum - (1/counts)*uni_delta_sum^2 )\n",
    "                            end\n",
    "                            if (uni_tau_squaresum - (1/counts)*uni_tau_sum^2) < 0\n",
    "                                uni_tau_error = 0\n",
    "                            else\n",
    "                                uni_tau_error = qmc_area /sqrt(counts^2-counts) * \n",
    "                                                sqrt( uni_tau_squaresum - (1/counts)*uni_tau_sum^2 )\n",
    "                            end\n",
    "                            \n",
    "                            if (non_uni_delta_squaresum - (1/counts)*non_uni_delta_sum^2) < 0\n",
    "                                non_uni_delta_error = 0\n",
    "                            else\n",
    "                                non_uni_delta_error = qmc_area /sqrt(counts^2-counts) * \n",
    "                                                      sqrt( non_uni_delta_squaresum - (1/counts)*non_uni_delta_sum^2 )\n",
    "                            end\n",
    "                            if (non_uni_tau_squaresum - (1/counts)*non_uni_tau_sum^2) < 0\n",
    "                                non_uni_tau_error = 0\n",
    "                            else\n",
    "                                non_uni_tau_error = qmc_area /sqrt(counts^2-counts) * \n",
    "                                                    sqrt( non_uni_tau_squaresum - (1/counts)*non_uni_tau_sum^2 )\n",
    "                            end\n",
    "                            \n",
    "                            output_file = \"\"\n",
    "\n",
    "                            if allocation == \"none\"\n",
    "                                output_file = \"res_for_alloc=$(allocation)\"*\n",
    "                                                  \",_max_rp=$(max_ratio),_max_P2=$(max_P2)\"\n",
    "                            elseif line_budget_factor == 0\n",
    "                                output_file = \"res_for_alloc=$(allocation)\"*\n",
    "                                                  \",_batt_bf=$(battery_budget_factor),_b_rel=$(battery_reliance)\"*\n",
    "                                                  \",_max_rp=$(max_ratio),_max_P2=$(max_P2)\"\n",
    "                            elseif battery_budget_factor == 0\n",
    "                                output_file = \"res_for_alloc=$(allocation)\"*\n",
    "                                                  \",_line_bf=$(line_budget_factor),_new_l=$(new_lines)\"*\n",
    "                                                  \",_max_rp=$(max_ratio),_max_P2=$(max_P2)\"\n",
    "                            end\n",
    "\n",
    "                            output_file = replace(output_file,Pair(\".\",\"p\"))*\".csv\"\n",
    "\n",
    "                            parameter_names = [\"qmc_area\",\n",
    "                                               \"uniform_delta_integral\", \"uniform_delta_error\",\n",
    "                                               \"uniform_tau_integral\", \"uniform_tau_error\",\n",
    "                                               \"non_uniform_delta_integral\", \"non_uniform_delta_error\",\n",
    "                                               \"non_uniform_tau_integral\", \"non_uniform_tau_error\"]\n",
    "                            parameter_values = [qmc_area,\n",
    "                                                uni_delta_integral, uni_delta_error,\n",
    "                                                uni_tau_integral, uni_tau_error,\n",
    "                                                non_uni_delta_integral, non_uni_delta_error,\n",
    "                                                non_uni_tau_integral, non_uni_tau_error]\n",
    "                            empty_column = [\" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \"]\n",
    "                            list = hcat(parameter_names,parameter_values,\n",
    "                                        empty_column, empty_column, empty_column, empty_column)\n",
    "                            emptyrow = [\" \" \" \" \" \" \" \" \" \" \" \"]\n",
    "                            sample_list = [\"P2\" \"prosumer_ratio\" \"uniform_influence_probability\" \"non_uniform_influence_probability\" \"delta_resilience_assessment\" \"tau_resilience_assessment\"]\n",
    "\n",
    "                            for key in keys(samples)\n",
    "                                newline = zeros(1,6)\n",
    "                                newline[1] = key[1]\n",
    "                                newline[2] = key[2]\n",
    "                                newline[3] = samples[key][1]\n",
    "                                newline[4] = samples[key][2]\n",
    "                                newline[5] = samples[key][3]\n",
    "                                newline[6] = samples[key][4]\n",
    "                                sample_list = vcat(sample_list,newline)\n",
    "                            end\n",
    "\n",
    "                            tab = vcat(list,emptyrow,sample_list)\n",
    "                            CSV.write(results_path*\"/\"*allocation_folder*\"/\"*output_file, Tables.table(tab),\n",
    "                                      delim=\"\\t\", header=false)\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struct to contain mean and error of a result\n",
    "struct error_struct\n",
    "    mean\n",
    "    error\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strategy_summary (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that calculates the resilience curve of a given response strategy from its resilience value at different parameter instances\n",
    "# the resilience values are the read from the files created by the above function and a new .csv file containing the curve summary is created in the parent directory\n",
    "function strategy_summary(results_path)\n",
    "    \n",
    "    @manipulate for b = button(\"Summarize allocation results\"; value=0)\n",
    "        if b > 0\n",
    "            b = 0\n",
    "\n",
    "            results_directory = readdir(results_path)\n",
    "            filter!(e->!occursin(\"csv\",e), results_directory)\n",
    "            @showprogress for allocation_folder in results_directory\n",
    "\n",
    "                uni_delta_res, uni_tau_res = Dict(), Dict()\n",
    "                non_uni_delta_res, non_uni_tau_res = Dict(), Dict()\n",
    "                variables = []\n",
    "\n",
    "                allocation_directory = readdir(results_path*\"/\"*allocation_folder)\n",
    "                filter!(e->occursin(\"csv\",e), allocation_directory)\n",
    "                for file in allocation_directory\n",
    "\n",
    "                    key = []\n",
    "\n",
    "                    allocation = string_value_from_filename(file, \"alloc\")\n",
    "                    line_budget_factor = value_from_filename(file, \"line_bf\")\n",
    "                    new_lines = value_from_filename(file, \"new_l\")\n",
    "                    battery_budget_factor = value_from_filename(file, \"batt_bf\")\n",
    "                    battery_reliance = value_from_filename(file, \"b_rel\")\n",
    "\n",
    "                    if allocation == \"none\"\n",
    "                        key = []\n",
    "                        variables = []\n",
    "                    elseif line_budget_factor == 0\n",
    "                        key = [battery_budget_factor, battery_reliance]\n",
    "                        variables = [\"battery_budget_factor\", \"battery_reliance\"]\n",
    "                    elseif battery_budget_factor == 0\n",
    "                        key = [line_budget_factor, new_lines]\n",
    "                        variables = [\"line_budget_factor\", \"new_lines\"]\n",
    "                    #else\n",
    "                        #key = (battery_budget_factor, battery_reliance, line_budget_factor, new_lines)\n",
    "                        #variables = [\"battery_budget_factor\", \"battery_reliance\", \"line_budget_factor\", \"new_lines\"]\n",
    "                    end\n",
    "                    \n",
    "                    thing = results_path*\"/\"*allocation_folder*\"/\"*file\n",
    "                    qmc = CSV.read(thing, DataFrame, transpose=true, limit=1, drop=collect(11:268))\n",
    "\n",
    "                    uni_delta_res[key] = error_struct(qmc.\"uniform_delta_integral\"[1],qmc.\"uniform_delta_error\"[1])\n",
    "                    uni_tau_res[key] = error_struct(qmc.\"uniform_tau_integral\"[1],qmc.\"uniform_tau_error\"[1])\n",
    "                    non_uni_delta_res[key] = error_struct(qmc.\"non_uniform_delta_integral\"[1],qmc.\"non_uniform_delta_error\"[1])\n",
    "                    non_uni_tau_res[key] = error_struct(qmc.\"non_uniform_tau_integral\"[1],qmc.\"non_uniform_tau_error\"[1])\n",
    "                end\n",
    "\n",
    "                output_file = \"summary_for_\"*allocation_folder*\".csv\"\n",
    "\n",
    "                lines = length(uni_delta_res)+1\n",
    "                columns = length(variables)+8\n",
    "\n",
    "                tab = Array{Any}(undef, lines, columns)\n",
    "                tab[1,1:length(variables)] = variables\n",
    "                tab[1,end-7:end] = [\"uniform_delta_resilience\",\"uniform_delta_error\",\n",
    "                                    \"uniform_tau_resilience\",\"uniform_tau_error\",\n",
    "                                    \"non_uniform_delta_resilience\",\"non_uniform_delta_error\",\n",
    "                                    \"non_uniform_tau_resilience\",\"non_uniform_tau_error\"]\n",
    "\n",
    "                i = 2\n",
    "                for key in betterkeys(uni_delta_res)\n",
    "                    tab[i,1:length(variables)] = key\n",
    "                    tab[i,end-7] = uni_delta_res[key].mean\n",
    "                    tab[i,end-6] = uni_delta_res[key].error\n",
    "                    tab[i,end-5] = uni_tau_res[key].mean\n",
    "                    tab[i,end-4] = uni_tau_res[key].error\n",
    "                    tab[i,end-3] = non_uni_delta_res[key].mean\n",
    "                    tab[i,end-2] = non_uni_delta_res[key].error\n",
    "                    tab[i,end-1] = non_uni_tau_res[key].mean\n",
    "                    tab[i,end] = non_uni_tau_res[key].error\n",
    "                    i += 1\n",
    "                end\n",
    "\n",
    "                CSV.write(results_path*\"/\"*output_file,Tables.table(tab),delim=\"\\t\",header=false)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status_quo_summary (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to generate the resilience value histogram of the status quo (non-adapted) power grid and save it as a .csv file\n",
    "function status_quo_summary(path)\n",
    "    \n",
    "    @manipulate for b = button(\"Summarize status quo results\"; value=0)\n",
    "        if b > 0\n",
    "            b = 0\n",
    "    \n",
    "            coordinate_list = readdir(path)\n",
    "\n",
    "            @showprogress for coordinate in coordinate_l^ist\n",
    "\n",
    "                file_list = readdir(path*\"/\"*coordinate)\n",
    "                filter!(e->!occursin(\"frac\",e), file_list)\n",
    "\n",
    "                worst_dist = []\n",
    "\n",
    "                for file in file_list\n",
    "                    \n",
    "                    thing = path*\"/\"*coordinate*\"/\"*file\n",
    "                    params = CSV.read(thing, DataFrame, transpose=true,\n",
    "                                      limit=1, drop=collect(24:45))\n",
    "                    quants = CSV.read(thing, DataFrame, skipto=26, header=25)\n",
    "\n",
    "                    s = params.\"line_safety\"[1]\n",
    "                    ftr = params.\"flowtest_runs\"[1]\n",
    "\n",
    "                    ps = quants.\"p-value\"\n",
    "                    qs = quants.\"delta p-quantile\"\n",
    "\n",
    "                    dist = worst_from_list(ps, qs)\n",
    "                    append!(worst_dist, dist)\n",
    "                end\n",
    "\n",
    "                frac = qf(worst_dist, 1)\n",
    "                CSV.write(path*\"/\"*coordinate*\"/frac.csv\",Tables.table([frac frac; frac frac]),delim=\"\\t\",header=false)       \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choose_output_path (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to select a directory interactively (useful when switching between devices)\n",
    "function choose_output_path(array)\n",
    "    @manipulate for path in array\n",
    "        global output_path = path\n",
    "        println(path)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choose_baseline (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to select a baseline value interactively\n",
    "# the baseline could be e.g. the resilience of the non-adapted power grid\n",
    "function choose_baseline(array)\n",
    "    @manipulate for tuple in array\n",
    "        global baseline = tuple\n",
    "        println(tuple)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qmc_visualizer (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to interactively show and export scatter plots of the QMC samples estimating the resilience basins\n",
    "function qmc_visualizer(path; sizzle=(1200,800),fontfac=1, dpi=100, cmap=:inferno) ###change cmap?\n",
    "    \n",
    "    IJulia.clear_output()\n",
    "    \n",
    "    directory = readdir(path)\n",
    "    filter!(e->!occursin(\"csv\",e), directory)\n",
    "    \n",
    "    @manipulate for allocation = dropdown( directory, label = \"allocation\"),\n",
    "                    #influence_density in [\"uniform\", \"non_uniform\"],\n",
    "                    sustainant in [\"tau\", \"delta\"]\n",
    "        \n",
    "        folder = readdir(path*\"/\"*allocation)\n",
    "        filter!(e->occursin(\"csv\",e), folder)\n",
    "        \n",
    "        LBF, NL, BBF, BR = [], [], [], []\n",
    "        \n",
    "        for filename in folder\n",
    "            if occursin(\"res_for_\",filename) == true\n",
    "                append!(LBF,value_from_filename(filename, \"line_bf\"))\n",
    "                append!(NL,value_from_filename(filename, \"new_l\"))\n",
    "                append!(BBF,value_from_filename(filename, \"batt_bf\"))\n",
    "                append!(BR,value_from_filename(filename, \"b_rel\"))\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        LBF = sort(unique(LBF))\n",
    "        NL = sort(unique(NL))\n",
    "        BBF = sort(unique(BBF))\n",
    "        BR = sort(unique(BR))\n",
    "        \n",
    "        @manipulate for line_budget_factor in LBF, new_lines in NL,\n",
    "                        battery_budget_factor in BBF, battery_reliance in BR,\n",
    "                        cbtoggle = toggle(label=\"plot colorbar\", value=0),\n",
    "                        b = button(\"Save as .PNG\"; value=0),\n",
    "                        size_h = spinbox(label=\"horizontal plot size\"; value=1220),\n",
    "                        size_v = spinbox(label=\"vertical plot size\"; value=1000)\n",
    "            \n",
    "            \n",
    "            plot_filename = \"\"\n",
    "            for filename in folder\n",
    "                if (occursin(\"res_for_\",filename) == true &&\n",
    "                    value_from_filename(filename, \"line_bf\") == line_budget_factor &&\n",
    "                    value_from_filename(filename, \"new_l\") == new_lines &&\n",
    "                    value_from_filename(filename, \"batt_bf\") == battery_budget_factor &&\n",
    "                    value_from_filename(filename, \"b_rel\") == battery_reliance )\n",
    "                    \n",
    "                    plot_filename = filename\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            thing = path*\"/\"*allocation*\"/\"*plot_filename\n",
    "            #values = CSV.read(thing, DataFrame, transpose=true, limit=1, drop=collect(10:267))\n",
    "            samples = CSV.read(thing, DataFrame, skipto=12, header=11)\n",
    "            \n",
    "            #res_col = \"$(influence_density)_$(sustainant)_integral\"\n",
    "            #err_col = \"$(influence_density)_$(sustainant)_error\"\n",
    "            \n",
    "            #res = round( values[:,res_col][1], digits=2)\n",
    "            #err = ceil( values[:,err_col][1], digits=2)\n",
    "\n",
    "            plot_filename = plot_filename[1:end-4]\n",
    "\n",
    "            max_P2 = value_from_filename(plot_filename, \"max_P2\")\n",
    "            max_ratio = value_from_filename(plot_filename, \"max_rp\")\n",
    "            \n",
    "            #x_delta_stable, y_delta_stable = [], []\n",
    "            #x_delta_unstable, y_delta_unstable = [], []\n",
    "            #x_tau_stable, y_tau_stable = [], []\n",
    "            #x_tau_unstable, y_tau_unstable = [], []\n",
    "            rps, nps, freqs = [], [], []\n",
    "            \n",
    "            number = size(samples)[1]\n",
    "            for L in 1:number\n",
    "                row = samples[L,:]\n",
    "                append!(rps,row.\"prosumer_ratio\"[1])\n",
    "                append!(nps,row.\"P2\"[1])\n",
    "                if sustainant == \"delta\"\n",
    "                    append!(freqs,row.\"delta_resilience_assessment\"[1])\n",
    "                elseif sustainant == \"tau\"\n",
    "                    append!(freqs,row.\"tau_resilience_assessment\"[1])\n",
    "                end\n",
    "            end\n",
    "\n",
    "            col = [(cgrad(cmap)[(freqs[i]/1)]) for i in 1:length(freqs)]\n",
    "            \n",
    "            col_func(rp,np) = freqs[ intersect( findall(e->e==rp, rps), findall(e->e==np, nps) )[1] ]\n",
    "            \n",
    "            cbool = :none\n",
    "            xticks=:auto\n",
    "            if cbtoggle == 1\n",
    "                cbool = :right\n",
    "                #xticks = [1]\n",
    "            end\n",
    "            \n",
    "            p = plot(size=sizzle, dpi=dpi,\n",
    "                     xlabel=\"\\$r_p\\$\",\n",
    "                     #ylim=(0,ceil(max_P2, digits=-1)), xlim=(0,ceil(max_ratio,digits=1)),\n",
    "                     ylabel=\"\\$n_p\\$\", legend=false, ytickfontrotation=90,\n",
    "                     labelfontsize=11*fontfac, legendfontsize=8*fontfac, tickfontsize=8*fontfac, framestyle=:box)\n",
    "            scatter!(rps, nps, markersize=25, colorbar=cbool, #color=col,\n",
    "                     marker_z = col_func, cmap =:inferno, colorbar_title=\"\\$\\\\alpha\\$\",\n",
    "                     colorbar_tickfontsize=8*fontfac, colorbar_titlefontsize=11*fontfac, clims=(0,1), xticks=xticks,\n",
    "                     right_margin=5*mm, markerstrokecolor=:grey)\n",
    "                \n",
    "                \n",
    "            if b > 0\n",
    "                savefig(\"Plots/$(sustainant)-based_QMC_samples\"*plot_filename[4:end])\n",
    "                b = 0\n",
    "            end\n",
    "            \n",
    "            p\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "texify (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to convert filename strings into readable text (without underscores) and format mathematical symbols in LaTeX\n",
    "function texify(string)\n",
    "    if string == \"line_budget_factor\"\n",
    "        return \"\\$\\\\phi_L\\$\"\n",
    "    elseif string == \"new_lines\"\n",
    "        return \"\\$\\\\varepsilon\\$\" #\"number of new lines \\$\\\\lambda\\$\"\n",
    "        \n",
    "    elseif string == \"battery_budget_factor\"\n",
    "        return \"\\$\\\\phi_B\\$\"\n",
    "    elseif string == \"battery_reliance\"\n",
    "        return \"\\$\\\\lambda\\$\"\n",
    "        \n",
    "    elseif string == \"line_adaptation_uniform\"\n",
    "        return \"uniform line adaptation\"\n",
    "    elseif string == \"battery_adaptation_uniform\"\n",
    "        return \"uniform battery adaptation\"\n",
    "        \n",
    "    elseif string == \"line_adaptation_closeness\"\n",
    "        return \"closeness-based line adaptation\"\n",
    "    elseif string == \"battery_adaptation_closeness\"\n",
    "        return \"closeness-based battery adaptation\"\n",
    "        \n",
    "    elseif string == \"line_adaptation_risktest\"\n",
    "        return \"flowtest-based line adaptation\"\n",
    "    elseif string == \"battery_adaptation_risktest\"\n",
    "        return \"flowtest-based battery adaptation\"\n",
    "    \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strategy_visualizer (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to interactively show and export line plots of the resilience curves showing the parameter dependency of the response strategies\n",
    "function strategy_visualizer(path)\n",
    "    \n",
    "    directory = readdir(path)\n",
    "    filter!(e->occursin(\"csv\",e), directory)\n",
    "    \n",
    "    better_directory = copy(directory)\n",
    "    for i in 1:length(directory)\n",
    "        better_directory[i] = directory[i][13:end-4]\n",
    "    end\n",
    "    \n",
    "    @manipulate for allocation = dropdown( better_directory, label = \"allocation\"),\n",
    "                    diagram in [\"colormap\", \"budget plot\", \"secondary plot\"],\n",
    "                    density in [\"probability (non-uniform)\", \"possibility (uniform)\"]\n",
    "        \n",
    "        thing = path*\"/summary_for_\"*allocation*\".csv\"\n",
    "        table = CSV.read(thing, DataFrame, header=true)\n",
    "        \n",
    "        if allocation == \"no_adaptation\"\n",
    "            println(\"uniform tau resilience: $(table.\"uniform_tau_resilience\"[1]) +- $(table.\"uniform_tau_error\"[1])\")\n",
    "            println()\n",
    "            println(\"non-uniform tau resilience: $(table.\"non_uniform_tau_resilience\"[1]) +- $(table.\"non_uniform_tau_error\"[1])\")\n",
    "        else\n",
    "            xlab = names(table)[1]\n",
    "            ylab = names(table)[2]\n",
    "            \n",
    "            x = unique(table[:,xlab])\n",
    "            y = unique(table[:,ylab])\n",
    "            \n",
    "            @manipulate for xchoice = toggles(x, value=x, label=\"filter values for $(xlab)\"),\n",
    "                            ychoice = toggles(y, value=y, label=\"filter values for $(ylab)\")\n",
    "\n",
    "                sort!(xchoice)\n",
    "                sort!(ychoice)\n",
    "\n",
    "                LX = length(xchoice)\n",
    "                LY = length(ychoice)\n",
    "\n",
    "                x_hidden = find_missing_values(x, xchoice)\n",
    "                y_hidden = find_missing_values(y, ychoice)\n",
    "\n",
    "                newtable = copy(table)\n",
    "\n",
    "                for i in x_hidden\n",
    "                    newtable = delete_rows(newtable, xlab, i)\n",
    "                end\n",
    "                for j in y_hidden\n",
    "                    newtable = delete_rows(newtable, ylab, j)\n",
    "                end\n",
    "\n",
    "                if density == \"possibility (uniform)\"\n",
    "                    delta = reshape(newtable.\"uniform_delta_resilience\", (LY,LX))\n",
    "                    delta_error = reshape(newtable.\"uniform_delta_error\", (LY,LX))\n",
    "                    tau = reshape(newtable.\"uniform_tau_resilience\", (LY,LX))\n",
    "                    tau_error = reshape(newtable.\"uniform_delta_error\", (LY,LX))\n",
    "                    R_max = 980.1\n",
    "                elseif density == \"probability (non-uniform)\"\n",
    "                    delta = reshape(newtable.\"non_uniform_delta_resilience\", (LY,LX))\n",
    "                    delta_error = reshape(newtable.\"non_uniform_delta_error\", (LY,LX))\n",
    "                    tau = reshape(newtable.\"non_uniform_tau_resilience\", (LY,LX))\n",
    "                    tau_error = reshape(newtable.\"non_uniform_delta_error\", (LY,LX))\n",
    "                    R_max = 1\n",
    "                end                \n",
    "                \n",
    "                R = []\n",
    "                R_err = []\n",
    "                R_label =\"\"\n",
    "\n",
    "                R = tau\n",
    "                R_err = tau_error\n",
    "                R_label = \"\\$R\\$\"          \n",
    "\n",
    "                xlabel = texify(xlab)\n",
    "                ylabel = texify(ylab)\n",
    "                \n",
    "                if diagram == \"colormap\"\n",
    "                    @manipulate for size_h = spinbox(label=\"horizontal plot size\"; value=1220),\n",
    "                                    size_v = spinbox(label=\"vertical plot size\"; value=1000),\n",
    "                                    budget_scale in [\"log\", \"linear\"],\n",
    "                                    secondary_scale in [\"linear\", \"log\"],\n",
    "                                    font_fac = spinbox(label=\"fontsize factor\"; value=2.),\n",
    "                                    clevels = spinbox(label=\"color levels\"; value=20)\n",
    "                        \n",
    "                        #R normalization according to max in x\n",
    "                        for i in 1:size(R)[2]\n",
    "                            R[:,i] /= maximum(R[:,i])\n",
    "                        end\n",
    "                        \n",
    "                        if budget_scale == \"log\"\n",
    "                            xscale = :log10\n",
    "                            xlabel = texify(xlab)*\" (logarithmic scale)\"\n",
    "                        else\n",
    "                            xscale = :identity\n",
    "                            xlabel = texify(xlab)\n",
    "                        end\n",
    "                        \n",
    "                        if secondary_scale == \"log\"\n",
    "                            yscale = :log10\n",
    "                            ylabel = texify(ylab)*\" (logarithmic scale)\"\n",
    "                        else\n",
    "                            yscale = :identity\n",
    "                            ylabel = texify(ylab)\n",
    "                        end\n",
    "                        \n",
    "                        contour(x, y, R, xlabel=xlabel, ylabel=ylabel, color=:inferno, fill=true,\n",
    "                                colorbar=:right, xticks=(x,x), yticks=(y,y), xtickfontrotation=90,\n",
    "                                xscale=xscale, yscale=yscale, colorbar_title=\"\\$R/R_{opt(\\\\phi_L)}\\$\",\n",
    "                                #clims=(0, R_max),\n",
    "                                framestyle=:box, size=(size_h, size_v),\n",
    "                                labelfontsize=11*font_fac, tickfontsize=8*font_fac,\n",
    "                                colorbar_tickfontsize=8*font_fac, colorbar_titlefontsize=11*font_fac,\n",
    "                                levels=clevels)\n",
    "\n",
    "                    end\n",
    "                    \n",
    "                elseif diagram == \"budget plot\"\n",
    "                    @manipulate for size_h = spinbox(label=\"horizontal plot size\"; value=1000),\n",
    "                                    size_v = spinbox(label=\"vertical plot size\"; value=1000),\n",
    "                                    budget_scale in [\"log\", \"linear\"],\n",
    "                                    R_scale in [\"log\", \"linear\"],\n",
    "                                    cmap in [:viridis, :thermometer, :coolwarm],\n",
    "                                    legend_loc in [:topleft, :bottomright],\n",
    "                                    font_fac = spinbox(label=\"fontsize factor\"; value=2.),\n",
    "                                    alph = spinbox(label=\"ribbon alpha\"; value=0.1)\n",
    "                        \n",
    "                        if budget_scale == \"log\"\n",
    "                            xscale = :log10\n",
    "                            xlabel = texify(xlab)*\" (logarithmic scale)\"\n",
    "                        else\n",
    "                            xscale = :identity\n",
    "                            xlabel = texify(xlab)\n",
    "                        end\n",
    "                        \n",
    "                        if R_scale == \"log\"\n",
    "                            Rscale = :log10\n",
    "                            R_label = \"\\$R\\$ (logarithmic scale)\"\n",
    "                        else\n",
    "                            Rscale = :identity\n",
    "                            R_label = \"\\$R\\$\"\n",
    "                        end\n",
    "                        \n",
    "                        styles =  [:solid, :dash, :dot, :dashdot,]\n",
    "    \n",
    "                        xp = plot(framestyle=:box)\n",
    "                        for i in 1:length(y)\n",
    "                            line_c = cgrad(cmap)[(i-1)/(length(y)-1)]\n",
    "                            line_s = mod_array(i,styles)\n",
    "                            plot!(x, R[i,:], xlabel=xlabel, ylabel=R_label, label=\"$(ylabel) = $(y[i])\",\n",
    "                                  leg=legend_loc, linewidth=2, linecolor=line_c, xticks=(x,x),\n",
    "                                  xtickfontrotation=90, xscale=xscale, yscale=Rscale, ribbon=R_err,\n",
    "                                  fillalpha=alph, fillcolor=line_c, linestyle=line_s, size=(size_h, size_v),\n",
    "                                  labelfontsize=11*font_fac, legendfontsize=7*font_fac, tickfontsize=8*font_fac)\n",
    "                        end\n",
    "                        for i in 1:length(y)\n",
    "                            line_c = cgrad(cmap)[(i-1)/(length(y)-1)]\n",
    "                            line_s = mod_array(i,styles)\n",
    "                            plot!(x, R[i,:], label=false, linewidth=2, linecolor=line_c, linestyle=line_s)\n",
    "                        end\n",
    "                        xp\n",
    "                    end                   \n",
    "                    \n",
    "                elseif diagram == \"secondary plot\"\n",
    "                    @manipulate for size_h = spinbox(label=\"horizontal plot size\"; value=1000),\n",
    "                                    size_v = spinbox(label=\"vertical plot size\"; value=1000),\n",
    "                                    secondary_scale in [\"linear\", \"log\"],\n",
    "                                    R_scale in [\"linear\", \"log\"],\n",
    "                                    cmap in [:redsblues, :vikO, :thermometer, :viridis, :coolwarm],\n",
    "                                    legend_loc in [:topleft, :bottomright],\n",
    "                                    font_fac = spinbox(label=\"fontsize factor\"; value=2.),\n",
    "                                    alph = spinbox(label=\"ribbon alpha\"; value=0.1)\n",
    "                                                    \n",
    "                    if secondary_scale == \"log\"\n",
    "                            yscale = :log10\n",
    "                            ylabel = texify(ylab)*\" (logarithmic scale)\"\n",
    "                        else\n",
    "                            yscale = :identity\n",
    "                            ylabel = texify(ylab)\n",
    "                        end\n",
    "                        \n",
    "                        if R_scale == \"log\"\n",
    "                            Rscale = :log10\n",
    "                            R_label = \"\\$R\\$ (logarithmic scale)\"\n",
    "                        else\n",
    "                            Rscale = :identity\n",
    "                            R_label = \"\\$R\\$\"\n",
    "                        end\n",
    "                        \n",
    "                        styles =  [:solid, :dash, :dot, :dashdot,]\n",
    "                    \n",
    "                        yp = plot(framestyle=:box)\n",
    "                        for j in 1:length(x)\n",
    "                            line_c = cgrad(cmap)[(j-1)/(length(x)-1)]\n",
    "                            line_s = mod_array(j,styles)\n",
    "                            plot!(y, R[:,j],xlabel=ylabel,ylabel=R_label, label=\"$(xlabel) = $(x[j])\", \n",
    "                                  leg=legend_loc, linewidth=2,linecolor=line_c, xticks=(y,y), xtickfontrotation=90,\n",
    "                                  xscale=yscale, yscale=Rscale, ribbon=R_err, fillalpha=alph,\n",
    "                                  fillcolor=line_c, linestyle=line_s, size=(size_h, size_v),\n",
    "                                  labelfontsize=11*font_fac, legendfontsize=7*font_fac, tickfontsize=8*font_fac)\n",
    "                        end\n",
    "                        for j in 1:length(x)\n",
    "                            line_c = cgrad(cmap)[(j-1)/(length(x)-1)]\n",
    "                            line_s = mod_array(j,styles)\n",
    "                            plot!(y, R[:,j], label=false, linewidth=2, linecolor=line_c, linestyle=line_s)\n",
    "                        end\n",
    "                        yp\n",
    "                        \n",
    "                    end     \n",
    "                end    \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strategy_visualizer_old (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deprecated version of the above plotting function\n",
    "function strategy_visualizer_old(path; subtract=[0,0], exp=-1, sizzle=(1000,1333), dpi=100, fontfac=1)\n",
    "    \n",
    "    IJulia.clear_output()\n",
    "    \n",
    "    directory = readdir(path)\n",
    "    filter!(e->occursin(\"csv\",e), directory)\n",
    "    \n",
    "    better_directory = copy(directory)\n",
    "    for i in 1:length(directory)\n",
    "        better_directory[i] = directory[i][13:end-4]\n",
    "    end\n",
    "    \n",
    "    @manipulate for allocation = dropdown( better_directory, label = \"allocation\")\n",
    "        \n",
    "        thing = path*\"/summary_for_\"*allocation*\".csv\"\n",
    "        table = CSV.read(thing, DataFrame, header=true)\n",
    "        \n",
    "        if allocation == \"no_adaptation\"\n",
    "            println(\"uniform delta resilience: $(table.\"uniform_delta_resilience\"[1]) +- $(table.\"uniform_delta_error\"[1])\")\n",
    "            println(\"uniform tau resilience: $(table.\"uniform_tau_resilience\"[1]) +- $(table.\"uniform_tau_error\"[1])\")\n",
    "            println()\n",
    "            println(\"non-uniform delta resilience: $(table.\"non_uniform_delta_resilience\"[1]) +- $(table.\"non_uniform_delta_error\"[1])\")\n",
    "            println(\"non-uniform tau resilience: $(table.\"non_uniform_tau_resilience\"[1]) +- $(table.\"non_uniform_tau_error\"[1])\")\n",
    "        else\n",
    "            xlab = names(table)[1]\n",
    "            ylab = names(table)[2]\n",
    "            \n",
    "            x = unique(table[:,xlab])\n",
    "            y = unique(table[:,ylab])\n",
    "\n",
    "            @manipulate for sustainant in [\"tau\", \"delta\"],\n",
    "                            mode in [\"probability (non-uniform)\", \"possibility (uniform)\"],\n",
    "                            error_mode in [\"absolute\", \"relative\"],\n",
    "                            resilience_colorscale_exp = dropdown(-20:1: -1, label=\"resilience_colorscale_exp\",\n",
    "                                                                 value=exp),\n",
    "                            resilience_colorlevels = spinbox(100:100:1200, label=\"resilience_colorlevels\",value=500),\n",
    "                            budget_scale in [\"logarithmic\", \"linear\"],\n",
    "                            R_scale in [\"logarithmic\", \"linear\"],\n",
    "                            xchoice = toggles(x, value=x, label=\"filter values for $(xlab)\"),\n",
    "                            ychoice = toggles(y, value=y, label=\"filter values for $(ylab)\"),\n",
    "                            margs = toggle(label=\"plot marginals\", value=1),\n",
    "                            b = button(\"Save as .PNG\"; value=0)\n",
    "\n",
    "                sort!(xchoice)\n",
    "                sort!(ychoice)\n",
    "\n",
    "                LX = length(xchoice)\n",
    "                LY = length(ychoice)\n",
    "\n",
    "                x_hidden = find_missing_values(x, xchoice)\n",
    "                y_hidden = find_missing_values(y, ychoice)\n",
    "\n",
    "                newtable = copy(table)\n",
    "\n",
    "                for i in x_hidden\n",
    "                    newtable = delete_rows(newtable, xlab, i)\n",
    "                end\n",
    "                for j in y_hidden\n",
    "                    newtable = delete_rows(newtable, ylab, j)\n",
    "                end\n",
    "\n",
    "                if mode == \"possibility (uniform)\"\n",
    "                    delta = reshape(newtable.\"uniform_delta_resilience\", (LY,LX))\n",
    "                    delta_error = reshape(newtable.\"uniform_delta_error\", (LY,LX))\n",
    "                    tau = reshape(newtable.\"uniform_tau_resilience\", (LY,LX))\n",
    "                    tau_error = reshape(newtable.\"uniform_delta_error\", (LY,LX))\n",
    "                    z_max = 980.1\n",
    "                elseif mode == \"probability (non-uniform)\"\n",
    "                    delta = reshape(newtable.\"non_uniform_delta_resilience\", (LY,LX))\n",
    "                    delta_error = reshape(newtable.\"non_uniform_delta_error\", (LY,LX))\n",
    "                    tau = reshape(newtable.\"non_uniform_tau_resilience\", (LY,LX))\n",
    "                    tau_error = reshape(newtable.\"non_uniform_delta_error\", (LY,LX))\n",
    "                    z_max = 1\n",
    "                end\n",
    "\n",
    "                z = []\n",
    "                title = \"\"\n",
    "                plot_name = \"\"\n",
    "\n",
    "                if sustainant == \"delta\"\n",
    "                    z = delta .-subtract[1]\n",
    "                    z_err = delta_error\n",
    "                    sus = \"\\$\\\\delta\\$\"\n",
    "                    R = \"\\$R_\\\\delta\\$\"\n",
    "                elseif sustainant == \"tau\"\n",
    "                    z = tau .-subtract[2]\n",
    "                    z_err = tau_error\n",
    "                    sus = \"\\$\\\\tau\\$\"\n",
    "                    R = \"\\$R_\\\\tau\\$\"\n",
    "                end                \n",
    "                \n",
    "                marg_err = copy(z_err)\n",
    "                if error_mode == \"relative\"\n",
    "                    z_err = z_err./z\n",
    "                    sep_cmap = true\n",
    "                    elabel = \"relative error of \"*R\n",
    "                elseif error_mode == \"absolute\"\n",
    "                    sep_cmap = true\n",
    "                    elabel = \"absolute error \\$\\\\sigma'_{R_\\\\$sustainant}\\$\"\n",
    "                end\n",
    "\n",
    "                zlabel = \"\\$R\\$\"\n",
    "                plot_name = \"$(sustainant)-based_resilience_for_$(texify(allocation))\"\n",
    "\n",
    "                xlog = false\n",
    "                zlog=false\n",
    "                xlabel = texify(xlab)\n",
    "                leg_xlabel = xlabel\n",
    "                ylabel = texify(ylab)\n",
    "                if budget_scale == \"logarithmic\"\n",
    "                    xlog = true\n",
    "                    xlabel = xlabel*\" (log scale)\"\n",
    "                end\n",
    "                if R_scale == \"logarithmic\"\n",
    "                    zlog = true\n",
    "                    zlabel = zlabel*\" (log scale)\"\n",
    "                end\n",
    "\n",
    "                if minimum(size(z)) < 2\n",
    "                    println(\"not enough parameter combos. Minimum is 2x2\")\n",
    "                else                    \n",
    "                    cp = contour_with_error(xchoice, ychoice, z, z_err; z_max=z_max, xlabel=xlabel, ylabel=ylabel,\n",
    "                                            zlabel=zlabel, elabel=elabel, xlog=xlog, sep_cmap=sep_cmap, dpi=dpi,\n",
    "                                            clevels=resilience_colorlevels, cexp=resilience_colorscale_exp)\n",
    "                    if margs == 0\n",
    "\n",
    "                        p = cp\n",
    "\n",
    "                    else\n",
    "\n",
    "                        mp = marginal_plot(xchoice, ychoice, z, marg_err; dpi=dpi,\n",
    "                                           xlab=leg_xlabel, xlabel=xlabel, ylabel=ylabel, zlabel=zlabel,\n",
    "                                           xlog=xlog, zlog=zlog)\n",
    "\n",
    "                        p = plot(cp, mp, layout=@layout[a; b], size=sizzle, dpi=dpi,\n",
    "                                 labelfontsize=11*fontfac, legendfontsize=8*fontfac, tickfontsize=8*fontfac,\n",
    "                                 titlefontsite=14*fontfac)\n",
    "\n",
    "                    end\n",
    "\n",
    "                    if b > 0\n",
    "                        savefig(\"Plots/\"*plot_name)\n",
    "                        b = 0\n",
    "                    end\n",
    "\n",
    "                    p\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting functions (not used in final article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glm_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that performs a glm fit on the resilience curve of a given response strategy\n",
    "function glm_fit(path; subtract=[0,0])\n",
    "    \n",
    "    directory = readdir(path)\n",
    "    filter!(e->occursin(\"csv\",e), directory)\n",
    "    \n",
    "    better_directory = copy(directory)\n",
    "    for i in 1:length(directory)\n",
    "        better_directory[i] = directory[i][13:end-4]\n",
    "    end\n",
    "    \n",
    "    @manipulate for allocation = dropdown( better_directory, label = \"allocation\"),\n",
    "                    sustainant in [\"tau\", \"delta\"]\n",
    "                    #mode\n",
    "                    #errors?\n",
    "        \n",
    "        thing = path*\"/summary_for_\"*allocation*\".csv\"\n",
    "        table = CSV.read(thing, DataFrame, header=true)\n",
    "        \n",
    "        table.\"delta_resilience\" .-=subtract[1]\n",
    "        table.\"tau_resilience\" .-=subtract[2]\n",
    "            \n",
    "        if sustainant == \"delta\"\n",
    "            newtable = rename(table, (names(table)[3] => \"res\" ))\n",
    "        elseif sustainant == \"tau\"\n",
    "            newtable = rename(table, (names(table)[4] => \"res\" ))      \n",
    "        end\n",
    "        \n",
    "        newtable = rename(newtable, (names(newtable)[1] => \"x\" ), ( names(newtable)[2] => \"y\" ))\n",
    "        \n",
    "        @manipulate for link_function = dropdown( [IdentityLink(), CauchitLink(), CloglogLink(), InverseLink(),\n",
    "                                          InverseSquareLink(), LogitLink(), LogLink(),\n",
    "                                          ProbitLink(), SqrtLink()] , label=\"link function\"),\n",
    "                        family = dropdown( [Normal(), Bernoulli(), Binomial(), Gamma(), Poisson()] , label=\"family\"),\n",
    "                        b = button(\"import fit formula\"; value=0)\n",
    "            if b > 0\n",
    "                b = 0\n",
    "                \n",
    "                fit = glm(form, newtable, family, link_function)\n",
    "                \n",
    "                println(fit)\n",
    "                #println(\"R-squared: \", r2(fit, variant=:devianceratio))\n",
    "            end\n",
    "        end        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lsq_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that performs a nonlinear least squares fit on the resilience curve of a given response strategy\n",
    "function lsq_fit(path; subtract=[0,0])\n",
    "    \n",
    "    directory = readdir(path)\n",
    "    filter!(e->occursin(\"csv\",e), directory)\n",
    "    \n",
    "    better_directory = copy(directory)\n",
    "    for i in 1:length(directory)\n",
    "        better_directory[i] = directory[i][13:end-4]\n",
    "    end\n",
    "    \n",
    "    @manipulate for allocation = dropdown( better_directory, label = \"allocation\"),\n",
    "                    sustainant in [\"tau\", \"delta\"]\n",
    "                    #mode\n",
    "                    #errors?\n",
    "        \n",
    "        thing = path*\"/summary_for_\"*allocation*\".csv\"\n",
    "        table = CSV.read(thing, DataFrame, header=true)\n",
    "        \n",
    "        table.\"delta_capacity\" .-=subtract[1]\n",
    "        table.\"tau_capacity\" .-=subtract[2]\n",
    "        \n",
    "        xlabel = names(table)[1]\n",
    "        ylabel = names(table)[2]\n",
    "        \n",
    "        xy = hcat(table[:,xlabel], table[:,ylabel])\n",
    "        z = []\n",
    "        \n",
    "        if sustainant == \"delta\"\n",
    "            z = table.\"delta_capacity\"\n",
    "        elseif sustainant == \"tau\"\n",
    "            z = table.\"tau_capacity\"\n",
    "        end\n",
    "        \n",
    "        @manipulate for cb = toggle(label=\"use parameter bounds\", value=1),\n",
    "                        b = button(\"apply fit formula\"; value=0)\n",
    "            if b > 0\n",
    "                b = 0\n",
    "                \n",
    "                if cb == 0\n",
    "                    fit = curve_fit(model, xy, z, Float64.(p0))\n",
    "                else\n",
    "                    fit = curve_fit(model, xy, z, Float64.(p0),\n",
    "                                    lower=Float64.(lower_bounds), upper = Float64.(upper_bounds))\n",
    "                end\n",
    "\n",
    "                params = DataFrame(parameter_value = fit.param, standard_deviation = stderror(fit))\n",
    "                println(sustainant*\" resilience for \"*allocation*\":\")\n",
    "                println(params)\n",
    "                println()\n",
    "            end            \n",
    "        end        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sustainant Comparison (not used in final article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resilience_scatter (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to compare the two differently defined resilience measures (delta and tau) in a scatter plot\n",
    "# the response strategies and their parameters are encoded as shape, color, and size\n",
    "function resilience_scatter(path; subtract=[0,0], cmap=:bilbao, min_size=3, max_size=10,\n",
    "                            mode=\"capacity\", scale=:log10, sizzle=(2000,1000), fontfac=1, lw=1, dpi=100,\n",
    "                            lens=false, lens_x1=25, lens_x2=900, lens_y1=18, lens_y2=900, reg=true)\n",
    "    \n",
    "    IJulia.clear_output()\n",
    "    \n",
    "    directory = readdir(path)\n",
    "    filter!(e->occursin(\"csv\",e), directory)\n",
    "    \n",
    "    better_directory = copy(directory)\n",
    "    for i in 1:length(directory)\n",
    "        better_directory[i] = directory[i][13:end-4]\n",
    "    end\n",
    "    \n",
    "    allocation_dict = Dict()\n",
    "\n",
    "    for allocation in better_directory\n",
    "        \n",
    "        thing = path*\"/summary_for_\"*allocation*\".csv\"\n",
    "        table = CSV.read(thing, DataFrame, header=true)\n",
    "        \n",
    "        table.\"delta_capacity\" .-=subtract[1]\n",
    "        table.\"tau_capacity\" .-=subtract[2]\n",
    "        \n",
    "        allocation_dict[allocation] = table\n",
    "    end\n",
    "    \n",
    "    shapes = [:square, :utriangle, :diamond, :dtriangle, :circle, :star5]\n",
    "    strats = better_directory\n",
    "    \n",
    "    dlabel = \"\\$\\\\delta\\$-based resilience $(mode) \\$R_\\\\delta\\$\"\n",
    "    tlabel = \"\\$\\\\tau\\$-based resilience $(mode) \\$R_\\\\tau\\$\"\n",
    "    if scale != :identity\n",
    "        dlabel = \"\\$\\\\delta\\$-based resilience $(mode) \\$R_\\\\delta\\$ (logarithmic scale)\"\n",
    "        tlabel = \"\\$\\\\tau\\$-based resilience $(mode) \\$R_\\\\tau\\$ (logarithmic scale)\"\n",
    "    end\n",
    "\n",
    "    p = plot(scale=scale, xlabel=dlabel, ylabel=tlabel, legend=:bottomright, size=sizzle, framestyle=:box,\n",
    "             dpi=dpi, legendfontsize=8*fontfac, guidefontsize=11*fontfac, tickfontsize=8*fontfac, gridlinewidth=lw)\n",
    "\n",
    "    low, high = 980.1, 0\n",
    "\n",
    "    j = 0\n",
    "    for allocation in sort(strats)\n",
    "\n",
    "        j+=1\n",
    "        allocation_index = j\n",
    "        table = allocation_dict[allocation]\n",
    "\n",
    "        deltas = table.\"delta_capacity\"\n",
    "        taus = table.\"tau_capacity\"\n",
    "\n",
    "        if mode == \"probability\"\n",
    "            deltas = deltas /= 980.1\n",
    "            taus = taus /= 980.1\n",
    "        end\n",
    "\n",
    "        if allocation != \"no_adaptation\"\n",
    "\n",
    "            xlabel = names(table)[1]\n",
    "            ylabel = names(table)[2]\n",
    "\n",
    "            x = table[:,xlabel]\n",
    "            y = table[:,ylabel]\n",
    "            \n",
    "            perm = sortperm(x, rev=true)\n",
    "            x = x[perm]\n",
    "            y = y[perm]\n",
    "            deltas = deltas[perm]\n",
    "            taus = taus[perm]\n",
    "            \n",
    "            if scale != :identity\n",
    "                L = length(deltas)\n",
    "                for i in 0:L-1\n",
    "                    if (deltas[L-i] <= 0) || (taus[L-i] <= 0)\n",
    "                        deleteat!(deltas, L-i)\n",
    "                        deleteat!(taus, L-i)\n",
    "                        deleteat!(x, L-i)\n",
    "                        deleteat!(y, L-i)\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            low = minimum([low, minimum(deltas), minimum(taus)])\n",
    "            high = maximum([high, maximum(deltas), maximum(taus)])\n",
    "            \n",
    "            y_max = maximum(y)\n",
    "            col = [(cgrad(cmap)[(y[i]/y_max)]) for i in 1:length(y)]\n",
    "\n",
    "            log_x = log10.(x)\n",
    "            x_max = maximum(log_x)\n",
    "            x_min = minimum(log_x)\n",
    "            x_span = x_max - x_min               \n",
    "            size_diff = max_size-min_size\n",
    "            size = [(min_size + size_diff*( (log_x[i]-x_min)/x_span )) for i in 1:length(x)]\n",
    "\n",
    "            scatter!(deltas, taus, label=texify(allocation), markersize=size, markercolor=col, markerstrokecolor=:grey,\n",
    "                     markerstrokewidth=1, markershape=shapes[allocation_index])\n",
    "        else\n",
    "            low = minimum([low, minimum(deltas), minimum(taus)])\n",
    "            high = maximum([high, maximum(deltas), maximum(taus)])\n",
    "            scatter!(deltas, taus, label=allocation, markersize=min_size, markercolor=:black, markerstrokecolor=:grey,\n",
    "                     markerstrokewidth=1, markershape=:x)\n",
    "        end \n",
    "    end\n",
    "    \n",
    "     plot!(smooth=reg)\n",
    "    \n",
    "    duo = [low, high]\n",
    "    plot!(duo, duo, linecolor=:grey, linealpha=0.5, linestyle=:dot, label=\"identity line\", linewidth=lw)\n",
    "    \n",
    "    if lens == true\n",
    "        lens!([lens_x1,lens_x2], [lens_y1,lens_y2], inset = (1, bbox(0.05, 0.05, 0.48, 0.49)),\n",
    "              scale=scale, gridlinewidth=lw, tickfontsize=8*fontfac)\n",
    "    end\n",
    "      \n",
    "    p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status_quo_visualizer (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that visualizes the fraction of suboptimal resilience values that occur without adaptaion\n",
    "# depending on the safety factor and number of flowtest runs which determine the initial power line capacities\n",
    "function status_quo_visualizer(path)\n",
    "    \n",
    "    c = readdir(path)\n",
    "    coordinate_list = [c[3:4];c[1:2];c[7:8];c[5:6];c[11:12];c[9:10,];c[15:16];c[13:14]] \n",
    "    \n",
    "    safeties = []\n",
    "    flowtest_runs = []\n",
    "    fail_fracs = []\n",
    "    \n",
    "    @showprogress for coordinate in coordinate_list\n",
    "        \n",
    "        \n",
    "        thing = path*\"/\"*coordinate*\"/frac.csv\"\n",
    "        table = CSV.read(thing, DataFrame, header=false, limit=1, drop=[2])\n",
    "        frac = table[1,1]\n",
    "        \n",
    "        append!(fail_fracs,frac)\n",
    "        \n",
    "        s = value_from_filename(coordinate, \"safety\")\n",
    "        ftr = value_from_filename(coordinate, \"flowtest_runs\")\n",
    "        \n",
    "        append!(safeties, s)\n",
    "        append!(flowtest_runs, ftr)\n",
    "    end\n",
    "\n",
    "    safeties = unique(safeties)\n",
    "    flowtest_runs = unique(flowtest_runs)\n",
    "\n",
    "    LS = length(safeties)\n",
    "    LF = length(flowtest_runs)\n",
    "\n",
    "    fail_fracs = reshape(fail_fracs, (LF,LS))       \n",
    "    \n",
    "    @manipulate for scale in [\"linear\", \"log\"],\n",
    "                    b = button(\"Save as .PNG\"; value=0)\n",
    "        \n",
    "        if scale == \"linear\"\n",
    "            zlabel=\"fraction of sustainant values < 1\"\n",
    "            title = \"Status quo test: \\n safety vs. flowtest_runs\"\n",
    "            plot_name = \"Status_quo_test_-_safety_vs_flowtest_runs\"\n",
    "            z = fail_fracs\n",
    "        elseif scale == \"log\"\n",
    "            zlabel=\"log (fraction of sustainant values < 1)\"\n",
    "            title = \"Status quo test: \\n safety vs. flowtest_runs \\n (logarithmic)\"\n",
    "            plot_name = \"Status_quo_test_-_safety_vs_flowtest_runs_(logarithmic)\"\n",
    "            z = log10.(fail_fracs)\n",
    "        end\n",
    "        \n",
    "        p = contour_marginals(safeties, flowtest_runs, z;\n",
    "                              xlabel=\"line_safety\", ylabel=\"flowtest_runs\", zlabel=zlabel ,\n",
    "                              title=title)\n",
    "\n",
    "        if b > 0\n",
    "            savefig(\"Plots/\"*plot_name)\n",
    "            b = 0\n",
    "        end\n",
    "\n",
    "        p\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
